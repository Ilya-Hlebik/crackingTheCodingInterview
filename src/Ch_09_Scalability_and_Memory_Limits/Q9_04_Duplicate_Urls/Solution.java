package Ch_09_Scalability_and_Memory_Limits.Q9_04_Duplicate_Urls;

public class Solution {
    public static void main(String[] args) {
        /*
        *
        *
        * 1)Split in 4000 chinks
        * 2)Process chunk and store each url in file with name = hash(u).txt . That means, that urls with the same hash will be in one file
        * 3)Go by each file and create hastable for each. This table will detect dups
        * 4)Store results in result file or db.
        *
        *
        *
        *
        *
        *
        * */
    }
}
